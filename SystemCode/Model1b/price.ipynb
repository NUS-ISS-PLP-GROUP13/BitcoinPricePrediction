{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "resident-divorce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "hawaiian-scholar",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "indoor-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "labeled-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "input_dim = 4\n",
    "hidden_dim_1 = 32\n",
    "hidden_dim_2 = 64 \n",
    "hidden_dim_3 = 512\n",
    "num_layers = 1\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "basic-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define our Bitcoin Price prediction model\n",
    "class BitcoinPrediction(nn.Module):\n",
    "    def __init__(self, input_dim,  hidden_dim_1, hidden_dim_2, hidden_dim_3, num_layers, output_dim):\n",
    "        super(BitcoinPrediction, self).__init__()\n",
    "        #neurons\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        self.hidden_dim_1 = hidden_dim_1\n",
    "        \n",
    "        self.hidden_dim_2 = hidden_dim_2\n",
    "        \n",
    "        self.hidden_dim_3 = hidden_dim_3\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.outpu_dim = output_dim\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_dim, hidden_dim_1, num_layers, batch_first = True)  \n",
    "        \n",
    "        self.lstm2 = nn.LSTM(hidden_dim_1, hidden_dim_2, num_layers, batch_first = True)\n",
    "        \n",
    "        self.dense = nn.Linear(hidden_dim_2, hidden_dim_3)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim_3, output_dim)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        # Initialize hidden state with zeros\n",
    "        h1 = torch.zeros(self.num_layers, X.size(0), self.hidden_dim_1).requires_grad_()\n",
    "\n",
    "        # Initialize cell state\n",
    "        c1 = torch.zeros(self.num_layers,X.size(0), self.hidden_dim_1).requires_grad_()\n",
    "        \n",
    "        # Initialize hidden state with zeros\n",
    "        h2 = torch.zeros(self.num_layers, X.size(0), self.hidden_dim_2).requires_grad_()\n",
    "\n",
    "        # Initialize cell state\n",
    "        c2 = torch.zeros(self.num_layers, X.size(0), self.hidden_dim_2).requires_grad_()\n",
    "        \n",
    "        output1, (h1, c1) = self.lstm1(X, (h1.detach(), c1.detach()))\n",
    "        \n",
    "        ouput2, (h2, c2) = self.lstm2(output1, (h2.detach(), c2.detach()))\n",
    "        \n",
    "        #just want last time step hidden states\n",
    "        out = self.dense(ouput2[:, -1, :])\n",
    "        \n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "tropical-introduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BitcoinPrediction(input_dim=input_dim, hidden_dim_1=hidden_dim_1,hidden_dim_2 = hidden_dim_2,hidden_dim_3 = hidden_dim_3,output_dim=output_dim, num_layers=num_layers)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "sticky-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \".model_bitcoinprice_prediction.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "usual-dominant",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(output_file, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "trained-extra",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "raised-romance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "scaler = load(open('scaler.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "unusual-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionScalar = MinMaxScaler()\n",
    "predictionScalar.min_ = scaler.min_[0]\n",
    "predictionScalar.scale_ = scaler.scale_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "structured-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input of list whose length equals to 4\n",
    "def reformat(input):\n",
    "    testD = np.reshape(input,(1, 4))\n",
    "    testD_scaled = scaler.transform(testD)\n",
    "    testD=testD_scaled.reshape(1,1,4)\n",
    "    x_test = torch.from_numpy(xxx).type(torch.Tensor)\n",
    "    return x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "democratic-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,x):\n",
    "    y = model(x)\n",
    "    y = predictionScalar.inverse_transform(y_test.detach().numpy().reshape(1,-1))\n",
    "    return y[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "sapphire-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to dimension (1,1,4)\n",
    "testD = [1021.750000, 1.018706, 27.000000, 351]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "impossible-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = reformat(testD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "coastal-basics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0130, 0.7783, 0.0255, 0.1298]]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "surface-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_ = predict(model, x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "sublime-exhibit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1010.1589"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-bacteria",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
